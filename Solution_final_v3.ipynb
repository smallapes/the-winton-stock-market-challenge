{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1><center><b>The Winton Stock Market Challenge Kaggle competition</b></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Content**:\n",
    "\n",
    " - - [Abstract](#abstract)\n",
    " - 1. [Introduction](#introduction)\n",
    "   - 1.1 [Data Overview](#data_overview)\n",
    "   - 1.2 [Evaluation](#evaluation)\n",
    "   - 1.3 [Submission](#submission)\n",
    "   - 1.4 [File Descriptions](#file_descriptions)\n",
    "   - 1.5 [Data Fields](#data_fields)\n",
    " - 2. [Preparation](#preparation)\n",
    "   - 2.1 [Imports](#imports)\n",
    "   - 2.2 [Global Vars](#global_vars)\n",
    "   - 2.3 [Data Loading](#data_loading)\n",
    " - 3. [Analysis](#analysis)\n",
    "   - 3.1 [Analysis Constrains](#analysis_constrains)\n",
    "   - 3.2 [Data Analysis](#data_analysis)\n",
    "   - 3.3 [Visual Data Analysis](#visual_data_analysis)\n",
    " - 4. [Preprocessing](#preprocessing)\n",
    "   - 4.1 [Feature Selection](#feature_selection)\n",
    "   - 4.2 [Data Preprocessing](#data_preprocessing)\n",
    "   - 4.3 [Visualize Data Preprocssesing](#visualize_data_preprocssesing)\n",
    " - 5. [Modelling](#modelling)\n",
    "   - 5.1 [Model Building](#model_building)\n",
    "   - 5.2 [Model Evaluation](#model_evaluation)\n",
    "   - 5.3 [Save Model Output](#save_model_output)\n",
    " - 6. [Remarks](#remarks)\n",
    "   - 6.1 [Improvements](#improvements)\n",
    "   - 6.2 [Final Notes](#final_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Abstract** <a class=\"anchor\" id=\"abstract\"></a>\n",
    "\n",
    " This is a solution for the [The Winton Stock Market Challenge Kaggle competition](https://www.kaggle.com/c/the-winton-stock-market-challenge).\n",
    "\n",
    " Since predicting stock market returns is notoriously hard, we will expect it to be difficult to beat\n",
    " a naive baseline model of just predicting mean returns of the training period. Also, since this is a\n",
    " *hiring competition* we will suspect the data set has been created in such a way, that dealing with\n",
    " important factors such as missing value imputation, numerical vs categorical features, colinearity,\n",
    " normalization, grouping and model robustness will be essential for competitors to demonstrate adequate\n",
    " skillsets in. Also, we note that we are here to win a Kaggle competition - not to make an actually viable\n",
    " trading algorithm.\n",
    "\n",
    " There where 832 teams participating in the Kaggle competition. This solution has a Private Score of 1727.86647 and\n",
    " a Public Score of 1769.92199 and would have ranked as number 4 (top 0.5%) on the Private Leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Introduction** <a class=\"anchor\" id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.1 Data Overview** <a class=\"anchor\" id=\"data_overview\"></a>\n",
    "\n",
    " In this competition, the challenge is to predict the return of a stock, given the history of the past few days.\n",
    "\n",
    " We provide 5-day windows of time, days D-2, D-1,\n",
    " D, D+1, and D+2. You are given returns in days\n",
    " D-2, D-1, and\n",
    " part of day D, and you are asked to predict the returns in the rest of day D, and in days\n",
    " D+1 and D+2.\n",
    "\n",
    " During day D, there is intraday return data, which are the returns at different points in\n",
    " the day. We provide\n",
    " 180 minutes of data, from t=1 to t=180. In the training set, you are given\n",
    " the full 180 minutes, in the test\n",
    " set just the first 120 minutes are provided.\n",
    "\n",
    " For each 5-day window, we also provide 25 features, Feature_1\n",
    " to Feature_25. These may or may not be useful\n",
    " in your prediction.\n",
    "\n",
    " Each row in the dataset is an arbitrary stock at an arbitrary 5 day time window.\n",
    "\n",
    " How these returns are calculated is defined by Winton, and will not to be revealed to you in this competition.\n",
    " The data set is designed to be representative of real data and so should bring about a number of challenges.\n",
    "\n",
    " How these returns are calculated is defined by Winton, and will not to be revealed to you in this competition.\n",
    " The data set is designed to be representative of real data and so should bring about a number of challenges.\n",
    "\n",
    " <img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/4504/media/Presentation1%20(1).jpg\" style=\"width: 700px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.2 Evaluation** <a class=\"anchor\" id=\"evaluation\"></a>\n",
    "\n",
    " Submissions are evaluated using the Weighted Mean Absolute Error. Each return\n",
    " you predicted is compared with the actual return. The formula is then\n",
    "\n",
    " $$\n",
    " MAE = \\frac{1}{n}\\sum\\limits_{i=1}^{n} w_i \\cdot \\left|y_i - \\hat{y_i}\\right|,\n",
    " $$\n",
    "\n",
    " where $w_i$ is the weight associated with the return, Weight_Intraday, Weight_Daily for intraday and daily returns,\n",
    " $i$, $y_i$ is the predicted return, $\\hat{y_i}$ is the actual return, n is the number of predictions.\n",
    "\n",
    " The weights for the training set are given in the training data. The weights for the test set are unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.3 Submission** <a class=\"anchor\" id=\"submission\"></a>\n",
    "\n",
    " The submission file should contain two columns: <font color=red>Id and Predicted.\n",
    " For each 5-day window, you need to predict 62\n",
    " returns. For example, for the first time window, you will predict 1_1, 1_2,\n",
    " to 1_62. 1_1 to 1_60 are predicting\n",
    " Ret_121 through Ret_180, 1_61 the prediction for\n",
    " Ret_PlusOne, and 1_62 the prediction for Ret_PlusTwo.\n",
    "\n",
    " The file should contain a header and have the following format:\n",
    "\n",
    "   <font color=red>Id, Predicted\n",
    "   1_1,0\n",
    "   1_2,0\n",
    "   1_3,0\n",
    "   1_4,0\n",
    "   ...\n",
    "   1_60,0\n",
    "   1_61,0\n",
    "   1_62,0\n",
    "   2_1,0\n",
    "   2_2,0\n",
    "   etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.4 File Descriptions** <a class=\"anchor\" id=\"file_descriptions\"></a>\n",
    "\n",
    " - train.csv - the training set, including the columns of:\n",
    "   - Feature_1 - Feature_25\n",
    "   - Ret_MinusTwo, Ret_MinusOne\n",
    "   - Ret_2 - Ret_120\n",
    "   - Ret_121 - Ret_180: target variables\n",
    "   - Ret_PlusOne, Ret_PlusTwo: target variables\n",
    "   - Weight_Intraday, Weight_Daily\n",
    "\n",
    " - test.csv - the test set, including the columns of:\n",
    "   - Feature_1 - Feature_25\n",
    "   - Ret_MinusTwo, Ret_MinusOne\n",
    "   - Ret_2 - Ret_120\n",
    "\n",
    "\n",
    " - sample_submission.csv - a sample submission file in the correct format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.5 Data Fields** <a class=\"anchor\" id=\"data_fields\"></a>\n",
    "\n",
    " - Feature_1 to Feature_25: different features relevant to prediction\n",
    " - Ret_MinusTwo: this is the return from the close of trading on day D-2 to the close of trading\n",
    "   on day D-1 (i.e. 1 day)\n",
    " - Ret_MinusOne: this is the return from the close of trading on day D-1 to the point at which the\n",
    "   intraday returns start on day D (approximately 1/2 day)\n",
    " - Ret_2 to Ret_120: these are returns over approximately one minute on day D.\n",
    "   Ret_2 is the return between t=1 and t=2.\n",
    " - Ret_121 to Ret_180: intraday returns over approximately one minute on day D. These are the target\n",
    "   variables you need to predict as {id}_{1-60}.\n",
    " - Ret_PlusOne: this is the return from the time Ret_180 is measured on day D to the close of\n",
    "   trading on day D+1. (approximately 1 day). This is a target variable you need to predict as {id}_61.\n",
    " - Ret_PlusTwo: this is the return from the close of trading on day D+1 to the close of trading\n",
    "   on day D+2 (i.e. 1 day) This is a target variable you need to predict as {id}_62.\n",
    " - Weight_Intraday: weight used to evaluate intraday return predictions Ret 121 to 180\n",
    " - Weight_Daily: weight used to evaluate daily return predictions (Ret_PlusOne and Ret_PlusTwo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Preparation** <a class=\"anchor\" id=\"preparation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1 Imports** <a class=\"anchor\" id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikitplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0k/_f4x7qm97mgb13xndshddklm0000gn/T/ipykernel_11485/429134068.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscikitplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mskplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myellowbrick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRank2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scikitplot'"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from IPython import get_ipython\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling as pp\n",
    "import cufflinks as cf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "from yellowbrick.features import Rank2D\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2. Global Vars** <a class=\"anchor\" id=\"global_vars\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***** OBS!: Using too few rows will crash QuantileTransformer! *****\n",
    "# Define debug mode\n",
    "#DEBUG = True\n",
    "DEBUG = False\n",
    "\n",
    "# Define visualization mode\n",
    "ANALYSE_DATA = True\n",
    "#ANALYSE_DATA = False\n",
    "SHOWPLOTS = True\n",
    "#SHOWPLOTS = False\n",
    "SHOWPLOTS_PROCCESED = True\n",
    "#SHOWPLOTS_PROCCESED = False\n",
    "\n",
    "# Define grid search mode\n",
    "#GRIDSEARCH = False\n",
    "GRIDSEARCH = True\n",
    "\n",
    "# Define paths\n",
    "ROOT_PATH = '/Users/lls/llsdata/winton/'\n",
    "DATA_PATH = ROOT_PATH + ''\n",
    "if not DEBUG:\n",
    "    TRAIN_PATH = ROOT_PATH + 'train.csv'\n",
    "    TEST_PATH = ROOT_PATH + 'test_2.csv'\n",
    "else:\n",
    "    TRAIN_PATH = ROOT_PATH + 'train_debug.csv'\n",
    "    TEST_PATH = ROOT_PATH + 'test_debug.csv'\n",
    "PROFILE_REPORT_PATH = DATA_PATH\n",
    "RESULT_CSV_PATH = DATA_PATH + 'submission.csv'\n",
    "\n",
    "# Define random seed\n",
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3 Data Loading** <a class=\"anchor\" id=\"data_loading\"></a>\n",
    "\n",
    " Here we perform initial data processing. We will be using Pandas Dataframes throughout the solution.\n",
    " We will need to sort the data frame by Feature_7 - the reason for this will become apparent in the\n",
    " [Data Analysis](#data_analysis) section. We will also aggregate the intraday return features Ret_2\n",
    " Ret_121 as a new feature called Ret_Agg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "# We need to sort by 'Feature_7'. See Data Analysis section.\n",
    "train_df.sort_values(by=['Feature_7'])\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# Aggregate intraday returns\n",
    "intraday_rets = []\n",
    "rets = ['Ret_MinusTwo', 'Ret_MinusOne']\n",
    "train_aggregated_rets = pd.DataFrame(columns=['Ret_Agg', 'Ret_Agg_Std', 'Ret_Std', ])\n",
    "test_aggregated_rets = pd.DataFrame(columns=['Ret_Agg', 'Ret_Agg_Std', 'Ret_Std'])\n",
    "\n",
    "for i in range(2, 121):\n",
    "    intraday_rets.append(f'Ret_{i}')\n",
    "\n",
    "train_aggregated_rets['Ret_Agg'] = train_df[intraday_rets].sum(axis=1)\n",
    "train_aggregated_rets['Ret_Agg_Std'] = train_df[intraday_rets].std(axis=1)\n",
    "train_aggregated_rets['Ret_Std'] = train_df[rets].std(axis=1)\n",
    "train_df = pd.concat([train_df, train_aggregated_rets], axis=1)\n",
    "\n",
    "test_aggregated_rets['Ret_Agg'] = test_df[intraday_rets].sum(axis=1)\n",
    "test_aggregated_rets['Ret_Agg_Std'] = test_df[intraday_rets].std(axis=1)\n",
    "test_aggregated_rets['Ret_Std'] = test_df[rets].std(axis=1)\n",
    "test_df = pd.concat([test_df, test_aggregated_rets], axis=1)\n",
    "\n",
    "# Prepare train, validation and test data\n",
    "features = ['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_5', 'Feature_6',\n",
    "            'Feature_7', 'Feature_8', 'Feature_9', 'Feature_10', 'Feature_11', 'Feature_12',\n",
    "            'Feature_13', 'Feature_14', 'Feature_15', 'Feature_16', 'Feature_17', 'Feature_18',\n",
    "            'Feature_19', 'Feature_20', 'Feature_21', 'Feature_22', 'Feature_23', 'Feature_24',\n",
    "            'Feature_25', 'Ret_MinusTwo', 'Ret_MinusOne', 'Ret_Agg', 'Ret_Agg_Std', 'Ret_Std', ]\n",
    "targets = ['Ret_PlusOne', 'Ret_PlusTwo']\n",
    "weights_intraday = 'Weight_Intraday'\n",
    "weights_daily = 'Weight_Daily'\n",
    "weights = [weights_intraday, weights_daily]\n",
    "features_targets = features + targets\n",
    "\n",
    "train_X_Y_df = train_df[features + targets]\n",
    "train_X_df = train_df[features]\n",
    "train_Y_df = train_df[targets]\n",
    "train_weights_daily_df = train_df[weights_daily]\n",
    "test_X_df = test_df[features]\n",
    "\n",
    "print('Data loaded')\n",
    "print(f'Shape of training feature data: {train_X_df.shape}')\n",
    "print(f'Shape of training target data: {train_Y_df.shape}')\n",
    "print(f'Shape of test feature data: {test_X_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Analysis** <a class=\"anchor\" id=\"analysis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1 Analysis Constrains** <a class=\"anchor\" id=\"analysis_constrains\"></a>\n",
    "\n",
    " In the interest of time we will focus only on predicting Ret_PlusOne and Ret_PlusTwo. To further justify this, we also note\n",
    " that intraday one min data is **_likely_** to be too noisy to be predictied by the data given in this competition. Hence we will only\n",
    " output predictions for {id}_61 and {id}_62 and output 0 for all of {id}_{1-60}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2 Data Analysis** <a class=\"anchor\" id=\"data_analysis\"></a>\n",
    "\n",
    " Here we will do initial data analysis. For each feature in the data set we look at the number of\n",
    " missing values, how many values are unique, how imbalanced the values are, how many potential\n",
    " outliers are contained in the values and if values in the training and test sets are disjoint.\n",
    "\n",
    " We define potential outliers as values which differs from the mean by more than 3 standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ANALYSE_DATA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0k/_f4x7qm97mgb13xndshddklm0000gn/T/ipykernel_11485/4202589585.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mANALYSE_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m# OBS: This is very compute intensive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Analysing data (this will take a while)...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ANALYSE_DATA' is not defined"
     ]
    }
   ],
   "source": [
    "def outliers(col):\n",
    "    std3 = col.std() * 3\n",
    "    mean = col.mean()\n",
    "    c = 0\n",
    "    for row in col:\n",
    "        if (abs(row - mean) > std3):\n",
    "            c = c + 1\n",
    "    return c\n",
    "\n",
    "def analyse_df(name, df_train, df_test=None, percentage=True):\n",
    "    test_set = ()\n",
    "    vals = []\n",
    "    vals_percent = []\n",
    "    for col in df_train:\n",
    "        if df_test is not None:\n",
    "            test_set = set(df_test[col])\n",
    "        switcher = {\n",
    "            'Missing': sum(df_train[col].isnull()),\n",
    "            'Unique': len(df_train[col].unique()),\n",
    "            'Imbalance': df_train[col].value_counts().values[0],\n",
    "            'Outlier': outliers(df_train[col]),\n",
    "            'Disjoint': set(df_train[col]).isdisjoint(test_set)\n",
    "        }\n",
    "        val = switcher.get(name)\n",
    "        vals.append(val)\n",
    "        vals_percent.append(val/len(df_train[col])*100)\n",
    "    if percentage:\n",
    "        res_df = pd.DataFrame(list(zip(vals, vals_percent)), columns=[name, f'{name} %'])\n",
    "    else:\n",
    "        res_df = pd.DataFrame(list(zip(vals)), columns=[name])\n",
    "    return res_df\n",
    "\n",
    "\n",
    "if ANALYSE_DATA:\n",
    "    # OBS: This is very compute intensive\n",
    "    print('Analysing data (this will take a while)...')\n",
    "    missing_data = analyse_df('Missing', train_X_Y_df)\n",
    "    unique_data = analyse_df('Unique', train_X_Y_df)\n",
    "    balanced_data = analyse_df('Imbalance', train_X_Y_df)\n",
    "    outlier_data = analyse_df('Outlier', train_X_Y_df)\n",
    "    disjoint_data = analyse_df('Disjoint', train_X_df, test_X_df, False)\n",
    "    analyse_data = pd.concat([pd.DataFrame(train_X_Y_df.columns), missing_data, unique_data,\n",
    "                              balanced_data, outlier_data, disjoint_data], axis=1)\n",
    "    print(\"Data Analysis:\")\n",
    "    print(analyse_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " From this analysis we observe the following:\n",
    "\n",
    " - Feature_1 has a very high number of missing values. It is likely that dropping this feature will improve model performance.\n",
    "\n",
    " - Feature_1, Feature_5, Feature_7, Feature_8, Feature_9, Feature_12, Feature_13, Feature_16 and Feature_20 contains few\n",
    "   uniqe values. These features are therefore determined to be categorical.\n",
    "\n",
    " - Feature_15 is highly imbalanced.\n",
    "\n",
    " - Besides being categorical, Feature_6 and Feature_7 are also distinct between the training and the test data sets.\n",
    "   However, Feature_6 is highly unique, whereas Feature_7 only contains relatively few unique values.\n",
    "\n",
    " This leaves Feature_7 as a special feature. We will try investigate this feature more thoroughly, by grouping returns by values of Feature_7 and\n",
    " look for a relationship in the sign of the returns to see if equal values of Feature_7 has correlated returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYSE_DATA:\n",
    "    feature_groups = defaultdict(list)\n",
    "    for i, row in train_df.iterrows():\n",
    "        val = row['Ret_PlusOne']\n",
    "        if val > 0:\n",
    "            feature_groups[row['Feature_7']].append(1)\n",
    "        else:\n",
    "            feature_groups[row['Feature_7']].append(-1)\n",
    "\n",
    "    freq = 0\n",
    "    for key, val in feature_groups.items():\n",
    "        frq0 = val.count(1)/len(val)\n",
    "        frq1 = len(val) - frq0\n",
    "        frq = max(frq0, frq1)\n",
    "        freq += frq/len(val)\n",
    "    freq = freq / len(feature_groups)\n",
    "\n",
    "    print(f'Frequence of return signs: {freq}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We observe that the sign of the returns within each group is almost 100% correlated. Regardless of what the nature of Feature_7 is,\n",
    " we have to account for this relationship when doing model cross-validation to avoid data leakage. Most likely, Feature_7\n",
    " has a relationship to time, which would explain why returns within the groups are correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.3 Visual Data Analysis** <a class=\"anchor\" id=\"visual_data_analysis\"></a>\n",
    "\n",
    " We will try to get a better understanding of the properties of the different features by plotting\n",
    " the features mutual correlations, the distributions of the features and regression plots for the features\n",
    " to see how they relate to the targets (for ease we are only looking at Ret_PluOne\n",
    " in the regression plots). To make data plotting faster, we will only look at a sample of 10% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(train_df: pd.DataFrame, test_df: pd.DataFrame, features: list,\n",
    "         transformer: Pipeline = None, frac: float = 0.1, label: str = ''):\n",
    "\n",
    "    train_data = train_df.sample(frac=frac, random_state=0)\n",
    "    test_data = test_df.sample(frac=frac, random_state=0)\n",
    "\n",
    "    if transformer is not None:\n",
    "        train_data = transformer.fit_transform(train_data[features])\n",
    "        train_data_df = pd.DataFrame(train_data, columns=features)\n",
    "        test_data = transformer.transform(test_data[features])\n",
    "        test_data_df = pd.DataFrame(test_data, columns=features)\n",
    "    else:\n",
    "        imputer = SimpleImputer(strategy='constant')\n",
    "        train_data_df = pd.DataFrame(imputer.fit_transform(\n",
    "            train_df[features]), columns=features)\n",
    "        test_data_df = pd.DataFrame(imputer.fit_transform(\n",
    "            test_df[features]), columns=features)\n",
    "\n",
    "    print(label)\n",
    "    fig, ax = plt.subplots(round(len(features) / 3), 3, figsize=(15, 15))\n",
    "    for i, ax in enumerate(fig.axes):\n",
    "        if i < len(features):\n",
    "            sns.distplot(train_data_df[features[i]], color='blue', ax=ax)\n",
    "            sns.distplot(test_data_df[features[i]], color='red', ax=ax)\n",
    "\n",
    "\n",
    "if SHOWPLOTS:\n",
    "    data_plot = train_X_Y_df.sample(frac=0.1, random_state=0)\n",
    "    imputer = SimpleImputer(strategy='constant')\n",
    "    data_plot_no_nan = pd.DataFrame(imputer.fit_transform(data_plot), columns=features_targets)\n",
    "    num_features = ['Feature_1', 'Feature_2', 'Feature_3', 'Feature_4', 'Feature_6',\n",
    "                    'Feature_11', 'Feature_14', 'Feature_15',\n",
    "                    'Feature_17', 'Feature_18', 'Feature_19',\n",
    "                    'Feature_21', 'Feature_22', 'Feature_23', 'Feature_24', 'Feature_25',\n",
    "                    'Ret_MinusTwo', 'Ret_MinusOne', 'Ret_Agg']\n",
    "    cat_features = ['Feature_5', 'Feature_7', 'Feature_8', 'Feature_9', 'Feature_10',\n",
    "                    'Feature_12', 'Feature_13', 'Feature_16', 'Feature_20']\n",
    "\n",
    "#     g = sns.PairGrid(data_plot_no_nan, vars=num_features)\n",
    "#     g.map_diag(sns.kdeplot)\n",
    "#     g.map_lower(sns.kdeplot)\n",
    "#     g.map_upper(plt.scatter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOWPLOTS:\n",
    "    # Correlation heatmap for all features and targets\n",
    "    print(\"Correlation heatmap:\")\n",
    "    f, ax = plt.subplots(figsize=(15, 15))\n",
    "    sns.heatmap(data_plot_no_nan.corr(), annot=True, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOWPLOTS:\n",
    "    # Correlation heatmap for numerical features\n",
    "    print(\"Correlation heatmap for numerical features:\")\n",
    "    f, ax = plt.subplots(figsize=(15, 15))\n",
    "    sns.heatmap(data_plot_no_nan[num_features].corr(), annot=True, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOWPLOTS:\n",
    "    # Correlation heatmap for categorical features\n",
    "    print(\"Correlation heatmap for categorical features:\")\n",
    "    f, ax = plt.subplots(figsize=(15, 15))\n",
    "    sns.heatmap(data_plot_no_nan[cat_features].corr(), annot=True, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOWPLOTS:\n",
    "    # Distributions\n",
    "    plot(train_X_df, test_X_df, features=features, label='Raw distributiions: Features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOWPLOTS:\n",
    "    # Regression plots\n",
    "    print(\"Regression plots:\")\n",
    "    fig, ax = plt.subplots(round(len(features) / 3), 3, figsize=(15, 15))\n",
    "    for i, ax in enumerate(fig.axes):\n",
    "        if i < len(features):\n",
    "            sns.regplot(x=features[i], y=targets[0], data=data_plot_no_nan, ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We observe first that - as expected when trying to predict stock returns - each feature shows very litle\n",
    " correlation with targets (apparent from both the correlation heatmap and the regression plots). Ve also observe\n",
    " a high correlation between some of the numerical features - in fact there seems to be 3 distinct clusters of correlation:\n",
    "\n",
    " - [Feature_3 - Feature_11] correlates with [Feature_3 - Feature_11]\n",
    " - [Feature_3 - Feature_11] correlates with [Feature_17 - Feature_25]\n",
    " - [Feature_17 - Feature_25] correlates with [Feature_17 - Feature_25]\n",
    "\n",
    " within the numerical features. This is probably not coincidental, and it is likely that an optimal solution needs to take advantage of these relationships.\n",
    " In this solution, however, we will not investigate it further. We also observer that most of the feature distributions does not\n",
    " appear to be gaussian. We will deal with these issues in the [Data Preprocessing](#data_preprocessing) section.\n",
    "\n",
    " Finally, we observe that Feature_13 has a relatively \"smooth\" distribution. We suspect that this feature\n",
    " might contain ordered information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Preprocessing** <a class=\"anchor\" id=\"preprocessing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.1 Feature Selection** <a class=\"anchor\" id=\"feature_selection\"></a>\n",
    "\n",
    " We will be using a robust preprocessing and modelling approach - hence, we include all features. Based on the above analysis, we split the features into\n",
    " numerical and categorical. We further split categorical into ordered (Feature_13) and unordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define final features\n",
    "num_features_final = ['Feature_2', 'Feature_3', 'Feature_4', 'Feature_6',\n",
    "                      'Feature_11', 'Feature_14',\n",
    "                      'Feature_17', 'Feature_18', 'Feature_19',\n",
    "                      'Feature_21', 'Feature_22', 'Feature_23', 'Feature_24', 'Feature_25',\n",
    "                      'Ret_MinusTwo', 'Ret_MinusOne', 'Ret_Agg', 'Ret_Agg_Std',\n",
    "                      'Ret_Std']\n",
    "\n",
    "cat_features_ordinal_final = ['Feature_13']\n",
    "\n",
    "cat_features_nominal_final = ['Feature_1', 'Feature_5', 'Feature_7', 'Feature_8', 'Feature_9', 'Feature_10',\n",
    "                              'Feature_12', 'Feature_15', 'Feature_16', 'Feature_20']\n",
    "\n",
    "cat_features_final = cat_features_ordinal_final + cat_features_nominal_final\n",
    "features_final = num_features_final + cat_features_final\n",
    "\n",
    "train_X_df = train_df[features_final]\n",
    "test_X_df = test_df[features_final]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.2 Data Preprocessing** <a class=\"anchor\" id=\"data_preprocessing\"></a>\n",
    "\n",
    " Here we define the piplines for preprocessing the input features and targets.\n",
    "\n",
    " We will impute both numerical and categorical features using a constant. This is chosen as the most conservative option.\n",
    "\n",
    " For numerical features, we will scale them using quantile range = [5, 95] as this approach is robust to outliers. Then we\n",
    " try to forces the distribution to be gaussian by using a quantile transformation. This is justified by the tendency of\n",
    " linear estimators to perform better on gaussian distributions. We also cut off values which lies\n",
    " more than 3 standard deviations from the centre to improve our handling of outliers.\n",
    "\n",
    " For ordered categorical features, we encode them using OrdinalEncoder to preserve the ordering.\n",
    "\n",
    " For unordered categorical features, we remove correlations between features by using PCA whitening and then one-hot encode so we can\n",
    " use models in the model building step that does not deal natively with categorical features.\n",
    "\n",
    " Finally, we normalize all features using l2-norm. The last step seems to improve l2-regulized regression significantly.\n",
    "\n",
    " *NOTE: We would have expected that PCA whitening of the numerical features would be beneficial for model performance since\n",
    " many of the numerical features are highly correlated. However, the opposite seems to be true. Perhaps the correlation clusters\n",
    " apparent in the correlation heatmap contains interesting information. We will leave it to a future improvement to try to\n",
    " investigate this further.*\n",
    "\n",
    " For target returns, we also use a quantile transformation to force the distribution of returns (which are not normally gaussian)\n",
    " into a gaussian distribution. We could also have used log transformation, but quantile transformation yields a better\n",
    " model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CutOff(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        X[X > 3] = 3\n",
    "        X[X < -3] = -3\n",
    "        return X\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant')),\n",
    "    ('scale', RobustScaler(quantile_range=[5, 95])),\n",
    "    ('quantile', QuantileTransformer(n_quantiles=300, output_distribution='normal', random_state=0)),\n",
    "    ('cutoff', CutOff()),  # Cut off at 3 standard deviations\n",
    "    ('norm', Normalizer(norm='l2'))\n",
    "])\n",
    "\n",
    "# Preprocessing for nominal categorical data\n",
    "cat_transformer_nominal = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant')),\n",
    "    ('pca', PCA(whiten=True, random_state=0)),\n",
    "    ('bins', KBinsDiscretizer(n_bins=100, encode='onehot', strategy='quantile')),\n",
    "    ('norm', Normalizer(norm='l2')),\n",
    "])\n",
    "\n",
    "# Preprocessing for ordinal categorical data\n",
    "cat_transformer_ordinal = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant')),\n",
    "    ('bins', KBinsDiscretizer(n_bins=100, encode='ordinal', strategy='quantile')),\n",
    "    ('norm', Normalizer(norm='l2')),\n",
    "])\n",
    "\n",
    "# Combined preprocessing for numerical and categorical data\n",
    "preprocessor_X = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features_final),        \n",
    "        ('cat_nom', cat_transformer_nominal, cat_features_nominal_final),\n",
    "        ('cat_ord', cat_transformer_ordinal, cat_features_ordinal_final)        \n",
    "    ])\n",
    "\n",
    "# Testing preprocessor\n",
    "preprocessor_X_shape = preprocessor_X.fit_transform(train_X_df).shape\n",
    "print(f'preprocessor_X output shape: {preprocessor_X_shape}')\n",
    "\n",
    "# Target transformer\n",
    "preprocessor_Y = Pipeline(steps=[\n",
    "    ('quantile', QuantileTransformer(n_quantiles=300, output_distribution='normal', random_state=0))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.3 Visualize Data Preprocessing** <a class=\"anchor\" id=\"visualize_data_preprocssesing\"></a>\n",
    "\n",
    " Here we look at the effects of preprocessing the features. Again, to make data plotting\n",
    " faster, we will only look at a sample of 10% of the data.\n",
    "\n",
    " We will try to get an idea about how the transformation affects the categorical values by reducing\n",
    " the dimension of the output using PCA (we use TruncatedSVD, which is suitable for sparse input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SHOWPLOTS_PROCCESED):\n",
    "    # Transform numerical features and targets\n",
    "    data_plot = train_X_Y_df.sample(frac=0.1, random_state=0)\n",
    "    imputer = SimpleImputer(strategy='constant')\n",
    "    data_plot_no_nan = pd.DataFrame(\n",
    "        imputer.fit_transform(data_plot), columns=features_targets)\n",
    "\n",
    "    num_transformed = num_transformer.fit_transform(\n",
    "        data_plot_no_nan[num_features_final])\n",
    "    viz_train_X_num_df = pd.DataFrame(\n",
    "        num_transformed, columns=num_features_final)\n",
    "    viz_train_Y_df = pd.DataFrame(\n",
    "        preprocessor_Y.fit_transform(train_Y_df), columns=targets)\n",
    "    viz_train_X_Y_num_df = pd.concat(\n",
    "        [viz_train_X_num_df, viz_train_Y_df], axis=1)\n",
    "\n",
    "    cat_transformed = cat_transformer_nominal.fit_transform(\n",
    "        num_transformer.fit_transform(data_plot_no_nan[cat_features_final]))\n",
    "    dim = 20\n",
    "    cat_features_pca = []\n",
    "    for i in range(0, dim):\n",
    "        cat_features_pca.append(f'{i}')\n",
    "    cat_transformed_pca = TruncatedSVD(\n",
    "        n_components=dim).fit_transform(cat_transformed)\n",
    "    viz_train_X_cat_df = pd.DataFrame(\n",
    "        cat_transformed_pca, columns=cat_features_pca)\n",
    "    viz_train_X_Y_cat_df = pd.concat(\n",
    "        [viz_train_X_cat_df, viz_train_Y_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SHOWPLOTS_PROCCESED):\n",
    "    # Distributions of numerical features after preprocssesing\n",
    "    plot(train_X_df, test_X_df, features=num_features_final, transformer=num_transformer,\n",
    "         label='After preproccssing numerical features: Distributions:')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SHOWPLOTS_PROCCESED):\n",
    "    # Regression plots of numerical features after preprocssesing\n",
    "    print(\"After preproccssing numerical features: Regression plots:\")\n",
    "    fig, ax = plt.subplots(\n",
    "        round(len(num_features_final) / 3), 3, figsize=(15, 15))\n",
    "    for i, ax in enumerate(fig.axes):\n",
    "        if i < len(num_features_final):\n",
    "            sns.regplot(\n",
    "                x=num_features_final[i], y=targets[0], data=viz_train_X_Y_num_df, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (SHOWPLOTS):\n",
    "    # Distributions of categorical features after preprocssesing\n",
    "    #plot(train_X_df, test_X_df, features=cat_features_final, transformer=cat_transformer, label='Preproccesed distributiions')\n",
    "\n",
    "if (SHOWPLOTS_PROCCESED):\n",
    "    # Distributions of categorical features after preprocssesing\n",
    "    print(\"After preproccssing categorical features: Distributions:\")\n",
    "    fig, ax = plt.subplots(round(dim / 3), 3, figsize=(15, 15))\n",
    "    for i, ax in enumerate(fig.axes):\n",
    "        if i < dim:\n",
    "            #sns.distplot(viz_train_X_num_df.iloc[i], ax=ax)\n",
    "            sns.distplot(viz_train_X_cat_df.iloc[i], ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SHOWPLOTS_PROCCESED):\n",
    "    # Regression plots categorical features after preprocssesing\n",
    "    print(\"After preproccssing categorical features: Regression plots:\")\n",
    "    fig, ax = plt.subplots(round(dim / 3), 3, figsize=(15, 15))\n",
    "    for i, ax in enumerate(fig.axes):\n",
    "        if i < dim:            \n",
    "            sns.regplot(x=cat_features_pca[i], y=targets[0], data=viz_train_X_Y_cat_df, ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (SHOWPLOTS_PROCCESED):\n",
    "    # Distributions of targets after preprocssesing\n",
    "    print(\"After preproccssing targets: Distributions:\")\n",
    "    fig, ax = plt.subplots(round(len(targets) / 3), 3, figsize=(15, 5))\n",
    "    for i, ax in enumerate(fig.axes):\n",
    "        if i < len(targets):\n",
    "            sns.distplot(viz_train_Y_df[targets[i]], ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We see that most distributions of the numerical features as well as the targets now appear \"smooth\" and more \"gaussian-like\". But we also observe\n",
    " that some features still have a some degree of imbalance. We will not deal with this issue further, but note that\n",
    " we could remove the problematic rows at the risk of loosing other valueable data points.\n",
    "\n",
    " It is not really easy to interpret the transposed output of the preprocessed categorical features. We will just note that nothing sticks out as odd.\n",
    "\n",
    " Finally, we observe that after the preprocessed step, the individual features still shows very little sign of any relationship with the targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Modelling** <a class=\"anchor\" id=\"modelling\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.1 Model Building** <a class=\"anchor\" id=\"model_building\"></a>\n",
    "\n",
    " We will focus on LinearSVR regression (wrapper for liblinear) with l2 regularization, as this method seems to deals particullary well\n",
    " with data with a very low Signal-to-noise ratio as one would expect from financial data. It is also a very fast algorithm (liblinear is heavily optimized).\n",
    " We will do a grid search with 5-fold GroupKFold cross-validation. As mentioned earlier, the fact that returns are not independent of Feature_7, we will have\n",
    " to group our cross-validation in order to avoid data leakage and hence overestimation of the CV performance*.\n",
    "\n",
    " Ideally, we should optimize using a loss function suitable for optimizing Weighed Mean Absolute Error (which is non-differentiable at 0). We did not\n",
    " prioritize this, and we still got reasonable results in the model scoring.\n",
    "\n",
    " (*)See: https://stats.stackexchange.com/questions/95797/how-to-split-the-dataset-for-cross-validation-learning-curve-and-final-evaluat\n",
    " and http://www.jmlr.org/papers/volume11/cawley10a/cawley10a.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Building model...')\n",
    "\n",
    "# Define initial model\n",
    "model = LinearSVR(epsilon=0.0, C=0.0005, loss='squared_epsilon_insensitive', random_state=0)  # 1727.860\n",
    "\n",
    "# Define model pipeline for multi output regression\n",
    "multi_out_reg = MultiOutputRegressor(model)\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor_X), ('multioutreg', multi_out_reg)])\n",
    "estimator = TransformedTargetRegressor(regressor=model_pipeline, transformer=preprocessor_Y)\n",
    "\n",
    "def WA(a, axis, weight):\n",
    "    # Adapted from function_base.py\n",
    "    a = np.asanyarray(a)\n",
    "    wgt = np.asanyarray(weight)\n",
    "    wgt = np.broadcast_to(wgt, (a.ndim-1)*(1,) + wgt.shape)\n",
    "    wgt = wgt.swapaxes(-1, axis)\n",
    "    n = len(a)\n",
    "    avg = np.multiply(a, wgt).sum(axis)/n\n",
    "\n",
    "    return avg\n",
    "\n",
    "def WMAE(y_true, y_pred, sample_weight):\n",
    "    # Adapted from regrssion.py\n",
    "    output_errors = WA(np.abs(y_pred - y_true), weight=sample_weight, axis=0)\n",
    "    avg = np.average(output_errors)\n",
    "\n",
    "    return avg\n",
    "\n",
    "if GRIDSEARCH:\n",
    "    # Define grid parameters to search\n",
    "    grid_params = {\n",
    "        'regressor__multioutreg__estimator__C': [0.0005, 0.001, 0.0015, 0.002]\n",
    "    }\n",
    "\n",
    "    # Define CV by grouping on 'Feature_7'\n",
    "    # See: https://stats.stackexchange.com/questions/95797/how-to-split-the-dataset-for-cross-validation-learning-curve-and-final-evaluat\n",
    "    #      http://www.jmlr.org/papers/volume11/cawley10a/cawley10a.pdf\n",
    "    group = train_X_df['Feature_7'].values\n",
    "    cv = list(GroupKFold(n_splits=5).split(train_X_df, train_Y_df, group))\n",
    "\n",
    "    # Define grid search scoring metric\n",
    "    scoring = 'neg_mean_absolute_error'\n",
    "\n",
    "    # Define grid search specified scoring and cross-validation generator\n",
    "    print('Running grid searc CV...')\n",
    "    gd_sr = GridSearchCV(estimator=estimator,\n",
    "                         param_grid=grid_params,\n",
    "                         scoring=scoring,\n",
    "                         cv=cv,\n",
    "                         # n_jobs=8,\n",
    "                         refit=True)\n",
    "\n",
    "    # Apply grid search and get parameters for best result\n",
    "    gd_sr.fit(train_X_df, train_Y_df)\n",
    "    best_params = gd_sr.best_params_\n",
    "    best_estimator = gd_sr.best_estimator_\n",
    "    score = -gd_sr.best_score_\n",
    "\n",
    "    print(f'Best parameters = {gd_sr.best_params_}')\n",
    "    print(f'Best MAE = {score}')\n",
    "\n",
    "else:\n",
    "    estimator.fit(train_X_df, train_Y_df)\n",
    "    best_estimator = estimator\n",
    "\n",
    "print('Done building model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.2 Model Evaluation** <a class=\"anchor\" id=\"model_evaluation\"></a>\n",
    "\n",
    " We evaluate the model by calculating the Weighted Mean Absolute Error of the model prediction and compare this to the\n",
    " baseline model of just predicting the returns as the mean of the returns in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on train and validation data\n",
    "pred_train_Y = best_estimator.predict(train_X_df)\n",
    "\n",
    "# Evaluate predictions on train and validation data and compare with baseline mean prediction\n",
    "mean_Y = [0, 0]\n",
    "mean_Y[0] = train_df[targets[0]].mean()\n",
    "mean_Y[1] = train_df[targets[1]].mean()\n",
    "\n",
    "train_mae = WMAE(train_Y_df, pred_train_Y, sample_weight=train_weights_daily_df)\n",
    "mean_Y_np = np.concatenate((np.full((train_Y_df.shape[0], 1), mean_Y[0]), np.full(\n",
    "    (train_Y_df.shape[0], 1), mean_Y[1])), axis=1)\n",
    "mean_mae = WMAE(train_Y_df, mean_Y_np, sample_weight=train_weights_daily_df)\n",
    "\n",
    "# Print scores\n",
    "print('WMAE score: LOWER is BETTER;)')\n",
    "print(f'WMAE of fitted model: {train_mae}')\n",
    "print(f'WMAE of baseline model: {mean_mae}')\n",
    "\n",
    "# Predict on test data\n",
    "pred_test_Y = best_estimator.predict(test_X_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We observe that the model seems to perform significantly better than the baseline model.\n",
    "\n",
    " To put this into perspective, there where 832 teams participating in the Kaggle competition. This solution has a Private Score of 1727.86647 and\n",
    " a Public Score of 1769.92199 and would have ranked as number 4 (top 0.5%) on the Private Leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5.3 Save Model Output** <a class=\"anchor\" id=\"save_model_output\"></a>\n",
    "\n",
    " Use:\n",
    "\n",
    " kaggle competitions submit -c the-winton-stock-market-challenge -f submission.csv -m \"message\"\n",
    "\n",
    " to submit the resulting submission.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = True\n",
    "#SAVE = False\n",
    "if SAVE:\n",
    "    # Create submission data\n",
    "    ids = []\n",
    "    preds = []\n",
    "    for i, row in test_df.iterrows():\n",
    "        for j in range(1, 61):\n",
    "            ids.append(f'{i+1}_{j}')\n",
    "            # OBS! We predict i_1 - i_60 as 0\n",
    "            preds.append(0)\n",
    "        ids.append(f'{i+1}_61')\n",
    "        preds.append(pred_test_Y[i][0])  # D+1\n",
    "        ids.append(f'{i+1}_62')\n",
    "        preds.append(pred_test_Y[i][1])  # D+2\n",
    "\n",
    "    submission_df = pd.DataFrame(\n",
    "        list(zip(ids, preds)), columns=['Id', 'Predicted'])\n",
    "    print(submission_df[(submission_df.Predicted != 0)].head(5))\n",
    "\n",
    "    # Save submission to csv file\n",
    "    submission_df.to_csv(RESULT_CSV_PATH, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Remarks** <a class=\"anchor\" id=\"remarks\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.1 Improvements** <a class=\"anchor\" id=\"improvements\"></a>\n",
    "\n",
    " We will briefly touch on a few possible improvements to potentially increase model performance:\n",
    "\n",
    "   - Ordinal vs nominal categorical variables: It would be interesting to investigate this further. Perhaps come up with\n",
    "     ways to auto-identify them (based on eg. distribution?).\n",
    "\n",
    "   - Ensemble: We did not investigate ensemble models. This is one of the usual ways to improve final models performance.\n",
    "\n",
    "   - Features interaction. Simple feature interaction did not improve model performance, but more selective feature interaction might do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.2 Final Notes** <a class=\"anchor\" id=\"final_notes\"></a>\n",
    "\n",
    " As stated above this solution fairs relatively favourable when compared to the Kaggle benchmark. However,\n",
    " there is a **lot** more to building a profitable trading model. Just because we can beat the baseline model does not\n",
    " guarantee the model can be exploited - ie, market frictions (trade cost, trade impact or overnight position costs) might\n",
    " adversely impact the models performance in a real trading setup. Ideally, we would need to design a trading system using the model\n",
    " and optimize a trading metric such as Sharp Ratio. We would also need to test such a system by successively retrain and retest\n",
    " it on a given set of time windows moving forward in time. On top of all this, we would of course also need an adequate portfolio optimization and risk\n",
    " management system."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "ubiquant",
   "language": "python",
   "name": "ubiquant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
